import{_ as i}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as n,a,o as s}from"./app-DJgFtDFQ.js";const t="/assets/image-8-BEPYaqgX.png",l="/assets/image-9-kPvWWyI6.png",p="/assets/image-7-7IYJIXdF.png",r="/assets/image-6-B8rQAl5P.png",o="/assets/image-AzVl89wL.png",g="/assets/image-1-Bh32YkEM.png",d="/assets/image-2-reO8hE9d.png",c="/assets/image-3-j_dZ4duv.png",u="/assets/image-4-m7iUD0nj.png",h="/assets/image-5-Bv2EjJya.png",m={};function k(A,e){return s(),n("div",null,e[0]||(e[0]=[a('<h1 id="大模型简介" tabindex="-1"><a class="header-anchor" href="#大模型简介"><span>大模型简介</span></a></h1><h2 id="_1-什么是大语言模型-llm" tabindex="-1"><a class="header-anchor" href="#_1-什么是大语言模型-llm"><span>1. 什么是大语言模型（LLM）</span></a></h2><p>你是否曾好奇，那些能与你对答如流、能帮你挥洒创意、甚至能编写复杂代码的AI，其背后究竟隐藏着怎样的奥秘？答案，就指向一个近年来炙手可热的概念——<strong>大语言模型（Large Language Model, LLM）</strong>。</p><p>从本质上讲，LLM是一种旨在深度理解并能灵活生成人类语言的人工智能模型。你可以将它想象成一位博览群书的&quot;超级学霸&quot;，通过学习海量的文本数据，从而掌握了语言的精髓。我们常说的LLM，通常指的是那些参数规模达到数百亿甚至更多的庞然大物。正是这海量数据的&quot;投喂&quot;，赋予了它们对语言前所未有的深刻理解力。</p><p>如今，群星璀璨的LLM领域中，国外有声名显赫的GPT、LLaMA、Gemini、Claude，国内则有DeepSeek、通义千问、文心一言、Kimi等一众实力派选手。</p><h3 id="_1-1-从量变到质变" tabindex="-1"><a class="header-anchor" href="#_1-1-从量变到质变"><span>1.1 <strong>从量变到质变</strong></span></a></h3><p>为了探寻性能的边界，研究者们踏上了一条&quot;大力出奇迹&quot;的道路，不断构建规模更为庞大的语言模型。例如，拥有1750亿参数的GPT-3和高达5400亿参数的PaLM，都是这条路上的里程碑。</p><p>尽管这些巨型模型在架构和预训练任务上与它们的前辈（如3.3亿参数的BERT和15亿参数的GPT-2）并无本质不同，但它们却展现出了截然不同的能力，尤其是在处理复杂任务时，迸发出了令人惊叹的潜力——这，就是所谓的&quot;<strong>涌现能力</strong>&quot;。</p><p>以GPT-3和GPT-2为例，前者可以通过上下文学习（in-context learning）来解决小样本任务，而后者在这方面则显得力不从心。正是这种从量变到质变的飞跃，让科研界为这些庞大的模型冠以&quot;大语言模型&quot;之名。而LLM的一个杰出应用，便是我们熟知的ChatGPT，它作为GPT系列模型在对话式应用上的一次大胆尝试，其流畅与自然的交互体验，彻底征服了世界。</p><h3 id="_1-2-llm的进化史" tabindex="-1"><a class="header-anchor" href="#_1-2-llm的进化史"><span>1.2 <strong>LLM的进化史</strong></span></a></h3><p>让机器理解语言的探索，可以追溯到上世纪90年代。那时的研究，主要采用统计学习方法，通过分析前文来预测下一个词，但在理解复杂的语言规则方面，始终存在着难以逾越的瓶颈。</p><p>转机出现在2003年，深度学习的先驱者Bengio发表了经典论文《A Neural Probabilistic Language Model》，首次将深度学习的思想注入语言模型。强大的神经网络，为计算机装上了一个理解语言的&quot;超级大脑&quot;，使其能更好地捕捉和理解语言中的复杂关系。</p><p>2018年，<strong>Transformer</strong>架构的横空出世，成为了LLM发展史上的分水岭。它就像一个高效的&quot;阅读引擎&quot;，让模型能够通过&quot;阅读&quot;海量文本，以前所未有的深度去理解语言的规则和模式。研究者们发现，随着模型规模的扩大（无论是增加模型参数还是使用更多数据），模型的性能都会显著提升，这一规律被称为&quot;<strong>规模法则（Scaling Law）</strong>&quot;。这一发现，正式宣告了大语言模型（LLM）时代的到来。</p><p>通常，一个大模型的构建包含三个核心阶段：<strong>预训练、后训练和在线推理</strong>。在2024年9月之前，大模型领域的&quot;规模法则&quot;主要存在于预训练阶段。然而，随着OpenAI o1模型的推出，人们惊喜地发现，后训练阶段的强化学习（RL Scaling Law）和在线推理阶段（Inference Scaling Law）也同样遵循着规模法则。这意味着，随着在各个阶段计算量的持续投入，大模型的性能仍在不断地向上突破。</p><figure><img src="'+t+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h2 id="_2-主流llm模型" tabindex="-1"><a class="header-anchor" href="#_2-主流llm模型"><span>2. 主流LLM模型</span></a></h2><p>大语言模型的发展历程虽短，其演进速度却令人叹为观止。截至2024年6月，全球已有上百种大模型竞相发布。下图梳理了从2019年至2024年6月，那些参数量超过百亿且具有重要影响力的大语言模型。</p><figure><img src="'+l+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>接下来，让我们重点介绍下国内外几个主流的大模型。</p><h3 id="_2-1-chatgpt" tabindex="-1"><a class="header-anchor" href="#_2-1-chatgpt"><span>2.1 ChatGPT</span></a></h3><p>谈及大模型，OpenAI及其GPT（Generative Pre-Training）系列是绕不开的篇章。GPT模型的核心理念，是利用一个仅包含解码器（decoder-only）的Transformer模型，将浩如烟海的世界知识压缩其中，使其成为一个能够&quot;记忆&quot;并运用这些知识的通用任务求解器。</p><p>其成功的关键在于两点：</p><ul><li><p>训练一个能够精准预测下一个词的decoder-only Transformer语言模型。</p></li><li><p>在第一点的基础上，持续、大规模地扩展模型的尺寸。</p></li></ul><p>OpenAI在LLM领域的探索历程，大致可以由下图清晰地展现。</p><figure><img src="'+p+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>目前，GPT系列已经演化出<strong>知识型</strong>与<strong>推理型</strong>两大技术分支。</p><p>2022年11月，OpenAI发布了基于GPT-3.5和GPT-4模型的会话应用ChatGPT。它凭借与人类交流时出色的表现，迅速在人工智能社区引发轰动。值得注意的是，ChatGPT本质上是一个LLM应用，它基于基座模型开发，与基座模型本身有着本质区别。ChatGPT上线后，用户增长势如破竹，仅用5天注册用户便突破100万，两个月后月活用户破亿，成为当时史上用户增长最快的消费级应用。</p><figure><img src="'+r+`" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>随着不断的迭代，ChatGPT的功能也日益丰富和强大：</p><ul><li><p><strong>插件系统</strong>：允许开发者创建工具来扩展ChatGPT的能力，实现了网页浏览、数据分析和第三方服务调用等功能。</p></li><li><p><strong>实时语音和视频对话</strong>：用户可以与AI进行自然的语音和视频交流，模型甚至支持手势识别和情感表达。</p></li><li><p><strong>多模态能力</strong>：能够分析和理解用户上传的图片、音频和视频，实现全面的多模态交互。</p></li><li><p><strong>自定义指令与记忆功能</strong>：能够记住用户此前的交互习惯和偏好，提供更具个性化的体验。</p></li><li><p><strong>GPT构建器平台</strong>：允许用户无需编程即可创建专用的AI助手，并支持自定义知识库和行为模式。</p></li><li><p><strong>数据分析与可视化</strong>：能够直接处理和分析用户上传的数据文件，并生成图表和可视化报告。</p></li><li><p><strong>知识型与推理型双模式</strong>：用户可以在不同模型（如知识型的GPT-4.5和推理型的o1/o3）之间切换，以满足不同场景的需求。</p></li><li><p><strong>思维链展示</strong>：在推理型模型中，用户可以选择性地查看模型的思考过程，从而更好地理解其推理步骤。</p></li></ul><p>2023年3月发布的GPT-4引入了多模态能力，其规模相比GPT-3.5的1750亿参数有了显著扩大（推测约1.8万亿参数），在解决复杂任务和评估任务上展现出巨大的性能飞跃。</p><p>2024年5月发布的GPT-4o（&quot;o&quot;代表&quot;omni&quot;，意为全能），具备了对文本、语音、图像三种模态的深度理解能力，其主要特点包括：多模态的无缝融合、快约2倍的响应速度、更富情感的语音表达以及降低约50%的API成本。</p><p>2024年7月发布的GPT-4o mini，则是一款面向消费级应用的轻量级模型，价格更亲民，适合日常对话和基础任务。</p><p>2025年2月发布的GPT-4.5，在知识广度、推理深度和创意表达方面均有显著提升，特别强化了对客观事实的准确性，并在情商方面表现优异。其上下文长度扩展至512K，是OpenAI最后一个非思维链模型。</p><p><strong>主流知识型模型对比：</strong></p><div class="language-plain line-numbers-mode" data-highlighter="shiki" data-ext="plain" data-title="plain" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>| 模型名称     | 上下文长度 | 特点                 | 知识截止日期 |</span></span>
<span class="line"><span>|--------------|------------|----------------------|--------------|</span></span>
<span class="line"><span>| GPT-4        | 16k        | 经济，专门对话       | 2021年9月    |</span></span>
<span class="line"><span>| GPT-4o       | 128k       | 多模态，速度快       | 2023年10月   |</span></span>
<span class="line"><span>| GPT-4.5      | 128k       | 最强知识型，精准度高 | 2023年10月   |</span></span>
<span class="line"><span>| GPT-4o mini  | 128k       | 轻量知识型，性价比高 | 2023年10月   |</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>2024年9月发布的o1-mini、o1-preview是专为复杂推理而设计的模型。它们在回答前会先生成一段（不公开的）思维链，优先确保推理步骤的正确性和结果的精确性。其特点包括：超强的推理能力、可靠的解题过程、优秀的问题分解能力以及自纠错机制。</p><p>2024年12月发布的o1，相较于o1-preview，能在更短的时间内响应。</p><p>2025年1月发布的o3-mini，可以显示部分思维链，与o1相比，在保持效果的同时，响应速度更快。</p><p><strong>GPT各版本模型对比：</strong></p><div class="language-plain line-numbers-mode" data-highlighter="shiki" data-ext="plain" data-title="plain" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>| 模型名称 | 上下文长度 | 特点             | 知识截止日期 |</span></span>
<span class="line"><span>|----------|------------|------------------|--------------|</span></span>
<span class="line"><span>| o1       | 128k       | 强推理能力，慢   | 2023年10月   |</span></span>
<span class="line"><span>| o1 mini  | 200k       | 轻量推理，中速   | 2023年10月   |</span></span>
<span class="line"><span>| o3 mini  | 200k       | 超轻量推理，最快 | 2023年10月   |</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>至此，OpenAI的模型战略形成了&quot;知识型&quot;和&quot;推理型&quot;两条相辅相成的产品线，让用户可以根据具体需求，选择最适合的模型类型。</p><h3 id="_2-2-claude" tabindex="-1"><a class="header-anchor" href="#_2-2-claude"><span>2.2 Claude</span></a></h3><p>Claude系列模型由从OpenAI离职的核心成员创办的Anthropic公司开发，是闭源大模型领域的另一位重量级玩家。</p><ul><li><p>最早的Claude于2023年3月15日发布。</p></li><li><p>2024年3月4日，更新至Claude 3系列，包括能力依次递增的Haiku、Sonnet和Opus，旨在满足不同层级的用户需求。</p></li><li><p>2024年10月，Anthropic发布了在推理和通用任务上显著提升的Claude 3.5 Sonnet。</p></li><li><p>2025年5月，Anthropic进一步发布了Claude 4.0系列，包括Claude 4 Sonnet和Claude 4 Opus。这两款均为混合推理模型，支持标准模式与推理思考模式切换，编码能力异常强大。同时，它们还支持多工具并行调用与精准指令解析，并升级了本地文件访问时的内存管理，强化了复杂任务的处理能力。</p></li></ul><p><strong>Claude模型特性一览：</strong></p><div class="language-plain line-numbers-mode" data-highlighter="shiki" data-ext="plain" data-title="plain" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>| 模型名称          | 上下文长度 | 特点                 |</span></span>
<span class="line"><span>|-------------------|------------|----------------------|</span></span>
<span class="line"><span>| Claude 3.5 Haiku  | 200k       | 速度最快             |</span></span>
<span class="line"><span>| Claude 4 Sonnet   | 200k       | 最强性能，领先推理力 |</span></span>
<span class="line"><span>| Claude 4 Opus     | 200k       | 性能强大，费用最高   |</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><figure><img src="`+o+`" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h3 id="_2-3-gemini" tabindex="-1"><a class="header-anchor" href="#_2-3-gemini"><span>2.3 Gemini</span></a></h3><p>Gemini系列语言大模型由科技巨头Google开发。</p><ul><li><p>2022年4月，其初始版本（当时名为PaLM，后更名为Gemini）发布。</p></li><li><p>2025年2月，Google发布了在性能和效率上均有显著提升的Gemini 2.0系列，包括Pro、Flash和Flash-Lite三个版本，分别适用于不同场景。同时，也推出了其推理模型Gemini 2.0 Flash Thinking。</p></li><li><p>2025年3月，Google发布了Gemini 2.5 Pro，性能进一步提升，尤其在推理能力和代码能力上进步显著。</p></li></ul><p><strong>Gemini模型特性一览：</strong></p><div class="language-plain line-numbers-mode" data-highlighter="shiki" data-ext="plain" data-title="plain" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>| 模型名称                   | 上下文长度 | 特点         |</span></span>
<span class="line"><span>|----------------------------|------------|--------------|</span></span>
<span class="line"><span>| Gemini 2.5 Pro             | 2M         | 性能最强     |</span></span>
<span class="line"><span>| Gemini 2.0 Flash           | 1M         | 低延迟，性能强 |</span></span>
<span class="line"><span>| Gemini 2.0 Flash-Lite      | 1M         | 性价比最高   |</span></span>
<span class="line"><span>| Gemini 2.0 Flash Thinking  | 1M         | 思维链展示   |</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><figure><img src="`+g+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h3 id="_2-4-文心一言" tabindex="-1"><a class="header-anchor" href="#_2-4-文心一言"><span>2.4 文心一言</span></a></h3><p>文心一言是基于百度&quot;文心大模型&quot;的知识增强语言大模型，于2023年3月在国内率先开启邀测。其基础模型&quot;文心大模型&quot;早在2019年便发布了1.0版，现已更新到4.0版本。更进一步看，文心大模型是一个庞大的家族，包括NLP、CV、跨模态、生物计算和行业大模型等。得益于此，文心一言的中文能力在国内处于领先水平。</p><p>文心一言网页版分为免费版（使用文心3.5）和专业版（使用文心4.0），同时也提供API供开发者调用。</p><figure><img src="'+d+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h3 id="_2-5-deepseek" tabindex="-1"><a class="header-anchor" href="#_2-5-deepseek"><span>2.5 DeepSeek</span></a></h3><p>DeepSeek是由国内的深度求索（DeepSeek）团队开发的开源大语言模型系列。它采用decoder-only架构，并融合了FlashAttention-2、RoPE位置编码、SwiGLU等先进技术，在多语言理解和代码生成等方面表现出色。</p><p><strong>模型发展历程：</strong></p><ul><li><p><strong>2023年11月12日</strong>：发布DeepSeek系列基础模型（7B和67B），同时发布专用代码生成模型DeepSeek-Coder。</p></li><li><p><strong>2024年3月15日</strong>：发布DeepSeek-V2系列，提升了多语言、长文本和推理能力，并发布了DeepSeek-MoE混合专家模型。</p></li><li><p><strong>2024年5月31日</strong>：发布DeepSeek-V2.5，性能进一步提升，上下文长度扩展至128K。</p></li><li><p><strong>2024年10月</strong>：发布DeepSeek-V3，在推理、多语言理解和创意生成方面显著提升。</p></li><li><p><strong>2025年2月</strong>：</p><ul><li><p>发布<strong>DeepSeekR1</strong>推理型大模型，是首个开源的推理型大模型，在多项基准测试中超越了o1系列。</p></li><li><p>发布<strong>DeepSeek-R1-Zero</strong>，直接在大规模强化学习（RL）上训练，无需SFT阶段，推理能力便十分出色。</p></li><li><p>同时开源了从DeepSeek-R1中蒸馏出的六个dense模型。</p></li></ul></li></ul><p>DeepSeek采用了一系列创新技术，如<strong>多头潜在注意力（MLA）和DeepSeekMoE</strong>，实现了高效推理和经济的训练成本。</p><p>凭借DeepSeekR1的卓越能力，DeepSeek迅速成为现象级爆火应用，仅用7天就完成了1亿用户的增长，打破了ChatGPT两个月的记录，成为史上用户增长最快的AI应用。目前，各大主流平台基本上都已接入DeepSeek。</p><figure><img src="'+c+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>以下就是DeepSeek的使用界面</p><figure><img src="'+u+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h3 id="_2-6-通义千问-来自阿里的开源力量" tabindex="-1"><a class="header-anchor" href="#_2-6-通义千问-来自阿里的开源力量"><span>2.6 通义千问：来自阿里的开源力量</span></a></h3><p>通义千问由阿里巴巴基于&quot;通义&quot;大模型研发，于2023年4月正式发布。</p><ul><li><p>2023年9月，阿里云开源了Qwen（通义千问）系列。</p></li><li><p>2024年6月6日，正式开源Qwen2。</p></li><li><p>2025年4月29日，发布了全新升级的Qwen3系列。</p></li></ul><p>Qwen系列均采用decoder-only架构，并结合了SwiGLU、RoPE、GQA等技术，是中文能力非常出色的开源模型系列。目前，已开源了从0.6B到235B的多种模型大小，上下文长度最高支持128k。Qwen3进一步增强了模型性能，覆盖119种语言和方言，并强化了代码、Agent及MCP（多模态内容理解）能力。</p><p>此外，阿里还开源了专门的代码模型（Qwen2.5-Coder）和数学模型（Qwen2.5-Math）。在推理大模型方面，于2024年11月发布并开源了QwQ-32B-Preview模型，后续在2025年3月发布的QwQ-32B，其性能可与更大参数的DeepSeek-R1相媲美。</p><p>以下是通义千问的使用界面： </p><figure><img src="'+h+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure>',74)]))}const _=i(m,[["render",k],["__file","大模型简介.html.vue"]]),f=JSON.parse('{"path":"/AI%E8%BF%9B%E9%98%B6%E4%B9%8B%E8%B7%AF/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AF%BC%E8%AE%BA/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B.html","title":"大模型简介","lang":"zh-CN","frontmatter":{"title":"大模型简介","tags":["AI","人工智能","生成式AI","大模型","LLM","DeepSeek","ChatGPT"],"description":"大模型简介 1. 什么是大语言模型（LLM） 你是否曾好奇，那些能与你对答如流、能帮你挥洒创意、甚至能编写复杂代码的AI，其背后究竟隐藏着怎样的奥秘？答案，就指向一个近年来炙手可热的概念——大语言模型（Large Language Model, LLM）。 从本质上讲，LLM是一种旨在深度理解并能灵活生成人类语言的人工智能模型。你可以将它想象成一位博览...","head":[["meta",{"property":"og:url","content":"https://xiucaistack.cn/AI%E8%BF%9B%E9%98%B6%E4%B9%8B%E8%B7%AF/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AF%BC%E8%AE%BA/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B.html"}],["meta",{"property":"og:site_name","content":"秀才的进阶之路"}],["meta",{"property":"og:title","content":"大模型简介"}],["meta",{"property":"og:description","content":"大模型简介 1. 什么是大语言模型（LLM） 你是否曾好奇，那些能与你对答如流、能帮你挥洒创意、甚至能编写复杂代码的AI，其背后究竟隐藏着怎样的奥秘？答案，就指向一个近年来炙手可热的概念——大语言模型（Large Language Model, LLM）。 从本质上讲，LLM是一种旨在深度理解并能灵活生成人类语言的人工智能模型。你可以将它想象成一位博览..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-07-01T08:53:37.000Z"}],["meta",{"property":"article:tag","content":"AI"}],["meta",{"property":"article:tag","content":"人工智能"}],["meta",{"property":"article:tag","content":"生成式AI"}],["meta",{"property":"article:tag","content":"大模型"}],["meta",{"property":"article:tag","content":"LLM"}],["meta",{"property":"article:tag","content":"DeepSeek"}],["meta",{"property":"article:tag","content":"ChatGPT"}],["meta",{"property":"article:modified_time","content":"2025-07-01T08:53:37.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"大模型简介\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-07-01T08:53:37.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"秀才\\",\\"url\\":\\"https://github.com/Percygu\\"}]}"]]},"headers":[{"level":2,"title":"1. 什么是大语言模型（LLM）","slug":"_1-什么是大语言模型-llm","link":"#_1-什么是大语言模型-llm","children":[{"level":3,"title":"1.1 从量变到质变","slug":"_1-1-从量变到质变","link":"#_1-1-从量变到质变","children":[]},{"level":3,"title":"1.2 LLM的进化史","slug":"_1-2-llm的进化史","link":"#_1-2-llm的进化史","children":[]}]},{"level":2,"title":"2. 主流LLM模型","slug":"_2-主流llm模型","link":"#_2-主流llm模型","children":[{"level":3,"title":"2.1 ChatGPT","slug":"_2-1-chatgpt","link":"#_2-1-chatgpt","children":[]},{"level":3,"title":"2.2 Claude","slug":"_2-2-claude","link":"#_2-2-claude","children":[]},{"level":3,"title":"2.3 Gemini","slug":"_2-3-gemini","link":"#_2-3-gemini","children":[]},{"level":3,"title":"2.4 文心一言","slug":"_2-4-文心一言","link":"#_2-4-文心一言","children":[]},{"level":3,"title":"2.5 DeepSeek","slug":"_2-5-deepseek","link":"#_2-5-deepseek","children":[]},{"level":3,"title":"2.6 通义千问：来自阿里的开源力量","slug":"_2-6-通义千问-来自阿里的开源力量","link":"#_2-6-通义千问-来自阿里的开源力量","children":[]}]}],"git":{"createdTime":1751360017000,"updatedTime":1751360017000,"contributors":[{"name":"Your Name","username":"Your Name","email":"380059082@qq.com","commits":1,"url":"https://github.com/Your Name"}]},"readingTime":{"minutes":13.44,"words":4032},"filePathRelative":"AI进阶之路/大模型应用开发/大模型导论/大模型简介.md","localizedDate":"2025年7月1日","autoDesc":true}');export{_ as comp,f as data};
